\section{General Information Useful for Training}
In the following chapters we will make use of different strategies:
\begin{itemize}
\item Class Weights (already talked about)
\item Data augmentation
\item Regularization
\item Dropout
\item Multiple activation functions
\item Multiple optimizers
\item Genetic Algorithms
\end{itemize}
In order to allow a better and faster reading of the tests done, in the following paragraph the mentioned strategies are discussed.

\subsection{Data Augmentation}
Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples via a number of random transformations that yield believable-looking images. The goal is that, at training time, your model will never see the exact same picture twice. This helps to expose the model to more aspects of the data so it can generalize better.
In Keras, this can be done by adding a number of data augmentation layers at the start of your model. In our model, we included the following transformation:

\begin{python}
data_augmentation = ks.Sequential(
    [
        layers.RandomFlip('horizontal'),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
        layers.RandomHeight(0.1),
        layers.RandomWidth(0.1)
    ]
)
\end{python}

\subsection{Regularization}
Regularization techniques are a set of best practices that actively impede the model’s ability to fit perfectly to the training data, with the goal of making the model perform better during validation. This is called “regularizing” the model, because it tends to make the model simpler, more “regular”, its curve smoother, more “generic”; thus it is less specific to the training set and better able to generalize by more closely approximating the latent manifold of the data.
A common way to mitigate overfitting is to put constraints on the complexity of a model by forcing its weights to take only small values, which makes the distribution of weight values more regular. This is called \textit{weight regularization}, and it’s done by adding to the loss function of the model a cost associated with having large weights. This cost comes in two flavors:
\begin{enumerate}
\item \textit{L1 regularization}—The cost added is proportional to the absolute value of the weight coefficients (the L1 norm of the weights).
\item \textit{L2 regularization}—The cost added is proportional to the square of the value of the weight coefficients (the L2 norm of the weights).
\item \textit{L1\_L2 regularization}—Combine L1 and L2.
\end{enumerate}

\subsection{Dropout}
Dropout is one of the most effective and most commonly used regularization techniques for neural networks; it was developed by Geoff Hinton and his students at the University of Toronto. Dropout, applied to a layer, consists of randomly dropping out (setting to zero) a number of output features of the layer during training.

In \textbf{keras} can be set using the \textit{layers.Dropout} function passing as parameter the \textit{dropout rate}. We tried different values for the dropout rate during our studies, anyway for the \textit{Pre-Trained Models} chapters it is always set to 0.5 if not otherwise specified.

\subsection{Activation Functions}
In the studies done in the following chapters we used three different activation functions:
\begin{itemize}
	\item \textit{ReLU}: 
	$ \max (0,x) $
	\item \textit{ELU}: $ \max (0.2x,x) $
%	\item \textit{Leaky ReLU}: 
%	$ 
%		f(x) = \begin{cases}
%		x \ \ \ \ \ \ \ \ \ \ \ x>0 \\
%		\alpha(\exp(x) -1) \ \ \ \ \ x\le0
%		\end{cases}
%	$
\end{itemize}
They will be useful in the genetic algorithm analysis done fore the \textit{scratch architecture} and the \textit{VGG16}

\subsection{Optimizers}
An optimizer is the mechanism through which the model will update itself based on the training data it sees, so as to improve its performance. In our project we make use of:

\begin{itemize}
	\item \textit{RMSprop}: the gist of RMSprop is to:
		\subitem - Maintain a moving (discounted) average of the square of gradients
		\subitem - Divide the gradient by the root of this average
		\subitem - It uses plain momentum, not Nesterov momentum.
	\item \textit{Adam}: stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.
\end{itemize}

\subsection{Genetic Algorithms}
Genetic algorithms are a family of search algorithms inspired by the principles of evolution in nature. By imitating the process of natural selection and reproduction, genetic algorithms can produce high-quality solutions for various problems involving search, optimization, and learning. At the same time, their analogy to natural evolution allows genetic algorithms to overcome some of the hurdles that are encountered by traditional search and optimization algorithms, especially for problems with a large number of parameters and complex mathematical representations. Thus, they come in handy for optimizing our networks.
In order to make use of genetic algorithms we must decide some components, which are:
\begin{itemize}
\item \textit{Genotype}: the \textit{genotype} is a collection of genes that are grouped into chromosomes. 
\item \textit{Population}: at any point in time, genetic algorithms maintain a population of individuals (i.e., chromosomes)– a collection of candidate solutions for the problem at hand.
\item \textit{Fitness Function}: at each iteration of the algorithm, the individuals are evaluated using a fitness function (also called the target function). This is the function we seek to optimize or the problem we attempt to solve.
\item \textit{Selection Algorithm}: after calculating the fitness of every individual in the population, a selection process is used to determine which of the individuals in the population will get to reproduce and create the offspring that will form the next generation.
\item \textit{Crossover Algorithm}: to create a pair of new individuals, two parents are chosen from the current generation, and parts of their chromosomes are interchanged (crossed over) to create two new chromosomes representing the offspring. 
\item \textit{Mutation Algorithm}: the purpose of the mutation operator is to periodically and randomly refresh the population, introduce new patterns into the chromosomes, and encourage search in uncharted areas of the solution space.
\item \textit{Elitism}: described in the following paragraph.
\end{itemize}
All of these components are implemented using the python library \textbf{deap}\footnote{https://deap.readthedocs.io/en/master/}.

\subsubsection{Elitism}
While the average fitness of the genetic algorithm population generally increases as generations go by, it is possible at any point that the best individual(s) of the current generation will be lost. This is due to the selection, crossover, and mutation operators altering the individuals in the process of creating the next generation. In many cases, the loss is temporary as these individuals (or better individuals) will be re-introduced into the population in a future generation.

However, if we want to guarantee that the best individual(s) always make it to the next generation, we can apply the optional elitism strategy. This means that the top \textit{n} individuals (\textit{n} being a small, predefined parameter) are duplicated into the next generation before we fill the rest of the available spots with offspring that are created using selection, crossover, and mutation. The elite individuals that were duplicated are still eligible for the selection process so they can still be used as the parents of new individuals.

Elitism is made possible in our code thanks to the function \textit{eaSimpleWithElitism}, which is a modification of the function \textit{eaSimple} present in the \textbf{Deap} framework.
