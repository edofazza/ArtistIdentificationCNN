\section{Conclusion}
The project reports a series of possible solutions for the artist recognition from a given paintings dataset. The solutions are therefore based on the use of multiple CNN networks, considering the current state of the art and the limitations of Colab.
First of all, we impemented several custom models, evaluating for each of them the validation and test accuracy and loss, and taking choices with the purpose of maximising performance and reacting to possible training issues. Starting from a very classical CNN, we also tested the effects of Droupout, Batch Normalization and Data Augmentation, we then defined and tested new architectures to tackle the artist classification task (namely Aggressive Downsampling techniques and custom Inception Modules). Most performing networks have been input to a hyper-paramters optimization procedure, and they have been analyzed to explainably visualize what they focus on and what is their robustness to occlusions.
Secondly we considered pre-trained models where we were able to obtain more satisfactory results than scratch and the best results were obtained thanks to VGG16, which with its simplicity manages better to classify than the larger networks that are trained with greater accuracy on \textit{imagenet}, which has a dataset very different from ours and perhaps this is the reason why we obtained slightly worse results for ResNets and Inception. 
Much more satisfactory results have been obtained thanks to the ensemble, reaching thanks to the aggregation of VGG16s models about 96\% of accuracy, the highest value reached in all our tests, bringing the model obtained to be our final model for the identification of the painters of the paintings. One thing to keep in mind talking about the ensemble is the fact that the genetic algorithm finds the conclusion immediately or almost immediately, this thing is related to a lucky starting point, but also, above all, to the very small number of genes that are part of the different chromosomes.
As for the state-of-art, we said in the introduction that the highest value obtained on the test accuracy was found by Nitin Viswanathan, and it was about 90\%, just few points below us. This makes our final result higher than the state-of-the-art.